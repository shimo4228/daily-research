# エージェントチーム版 評価レポート (2026-02-19)

## 概要

daily-research パイプラインの品質向上を目的に、Opus オーケストレーター + サブエージェント構成（エージェントチーム版）を設計・実装・評価した。結果として費用対効果が低く、チーム版は棄却。テーマ選定のみ Opus に分離する軽量2パス方式を採用した。

## 背景と動機

ポッドキャスト「池友小原のディープなAIニュース」での議論がきっかけ:

- **尾原氏**: Playwright + ヘッドレス Chrome で Gemini Deep Research を1日200回自動実行
- **池友氏**: Manus のワイドリサーチで並列エージェント100体、Claude Agent Team でサブエージェント分散

Google Research のマルチエージェント研究も参考にした:

- 中央集権型（オーケストレーター）: エラー増幅 4.4倍（独立並列の17.2倍より大幅に低い）
- Plan-and-Execute（賢いモデルが計画、安いモデルが実行）で90%コスト削減

これらから「Opus 司令塔 + Sonnet リサーチャー/ライター」のチーム構成を設計した。

## アーキテクチャ

```
Opus オーケストレーター (--model opus --agent)
├── config.toml 読み込み
├── past_topics.json 読み込み
├── Mem0 検索 ×3 (テーマ履歴・手法・ソース)
├── WebSearch でトレンド調査
├── テーマ選定 (tech + personal)
├── Task: researcher (tech) ──→ [意図: Sonnet / 実際: Haiku]
├── Task: researcher (personal) ──→ [同上]
├── Task: writer (tech) ──→ [同上]
├── Task: writer (personal) ──→ [同上]
├── Read ×2 (レポート検証)
├── past_topics.json 更新
└── Mem0 記録 ×3+
```

### 重大な設計ミス: サブエージェントのモデルフォールバック

`--model opus` はメインエージェントにのみ適用され、**Task ツールで spawn されたサブエージェントには継承されなかった**。結果として researcher/writer は全て Haiku で実行された。

意図した構成: Opus (司令塔) → Sonnet (リサーチ・執筆)
実際の構成: Opus (司令塔) → **Haiku** (リサーチ・執筆)

## 評価結果

### 定量比較 (同日 2026-02-19)

| 指標 | Sonnet シングルパス | チーム版 (Opus + Haiku) |
|------|-------------------|----------------------|
| 所要時間 | 7分 | 62分 (9倍) |
| コスト | $1.78 | $3.53 (2倍) |
| Output tokens | 13,906 | 42,803 (3倍) |
| Cache creation | 83K | 202K |
| レポート数 | 2 | 2 |
| 月間コスト (毎日) | ~$54 | ~$54 + $106 = $160 |

### LLM-as-Judge ブラインド評価

2026-02-18〜19 の全12レポート (Sonnet 4本 + Team 8本) をブラインドで採点。

**Tech トラック (02-18)**

| 順位 | レポート | 正体 | 合計 (/70) | テーマ選定 (/10) |
|------|---------|------|-----------|----------------|
| 1 | メモリインフラ | Team | 60 | 9 |
| 2 | AGENTS.md | Team | 56 | 9 |
| 3 | Heretic abliteration | Team | 55 | 7 |
| 4 | Chrome DevTools MCP | Sonnet | 50 | 6 |

**Personal トラック (02-18)**

| 順位 | レポート | 正体 | 合計 (/70) | テーマ選定 (/10) |
|------|---------|------|-----------|----------------|
| 1 | 瞑想×分子再プログラミング | Team | 61 | 9 |
| 2 | 能動推論×VR社会認知 | Team | 58 | 8 |
| 3 | Bio-Intelligence | Team | 54 | 8 |
| 4 | 内受容感覚 | Sonnet | 52 | 7 |

**Tech トラック (02-19)**

| 指標 | Sonnet | Team | 差 |
|------|--------|------|-----|
| 合計 | 54 | 58 | +4 |

**Personal トラック (02-19)**

| 指標 | Sonnet | Team | 差 |
|------|--------|------|-----|
| 合計 | 56 | 56 | 0 |

### 統合スコア (全12本)

| 指標 | Sonnet (n=4) | Team (n=8) | 差 |
|------|-------------|-----------|-----|
| 平均合計 | 53.0 | 57.1 | +4.1 (+8%) |
| テーマ選定 | 6.5 | 8.3 | +1.8 (+28%) |
| 順位 | 全4本が最下位 | 上位を独占 | — |

## 分析

### チーム版が優れていた点

1. **テーマ選定** (+28%): Opus の深い推論による多軸スコアリングが効果的。Team 版はニッチだが価値の高いトピックを選定する傾向
2. **ソース品質**: 若干の向上。情報源の多様性が高い
3. **テーマの関連性**: config.toml の関心ドメインとの適合度が高い

### チーム版が劣っていた / 差がなかった点

1. **具体性** (Specificity): Sonnet の方がやや高い場合あり。Haiku リサーチャーの要約品質の限界
2. **散文品質**: ほぼ同等
3. **リサーチの深さ**: ほぼ同等

### 構造的な問題

1. **委任のオーバーヘッド > 並列化のメリット**
   - Opus オーケストレーターがサブエージェントの結果をまるごと自身のコンテキストに蓄積
   - 各 Task の起動・応答待ちのラウンドトリップ
   - Opus は Sonnet より token 生成が遅い
   - Mem0 の 6回以上の API ラウンドトリップ

2. **サブエージェントのモデル問題**
   - researcher/writer が Haiku で動作（Sonnet の意図）
   - Claude Code の Task ツールがモデル指定を継承しない仕様
   - Haiku でも Opus の指示精度のおかげで品質はそこそこ出たが、Sonnet なら更に差が出た可能性

3. **コスト構造**
   - Opus のコスト ($3.31) が全体の 94% を占める
   - Haiku リサーチャーは安い ($0.21) が、価値の大部分は Opus のテーマ選定に集中

## 結論と判断

### 棄却の理由

品質差 +6〜8% に対して、コスト 2倍・時間 9倍は見合わない。月額換算で $106 の追加コスト。

### 教訓

1. **Opus の価値はテーマ選定に集中** — フルオーケストレーターとしては費用対効果が悪い。得意な部分だけ切り出して使う方が合理的
2. **サブエージェントのモデル継承を事前検証せよ** — `--model` の適用範囲を実測で確認すべきだった
3. **LLM-as-Judge は有効な評価手法** — ブラインド評価で主観バイアスを排除できた

### 後続アクション (実施済み)

- チーム版チェーン実行を削除
- Opus テーマ選定のみ軽量2パス方式として再実装 (Pass 1: Opus テーマ選定 → Pass 2: Sonnet リサーチ・執筆)
- コード自体は git history (`a79074e`) で復元可能
- 2パス方式の有効性は別途検証中 → Sonnet 一括のベースライン評価を先に実施する方針に変更 (2026-02-20)

## 関連ドキュメント

- `docs/progress/postmortem-2026-02-19.md` — Mem0・2パス・チーム版の同時実装障害のポストモーテム
- `docs/plans/THREE-PASS-PLAN.md` — 3パス化の将来拡張案
- `prompts/theme-selection-prompt.md` — 設計メモ (モデル配置の根拠)
- `docs/archive/SESSION_HANDOFF.md` — 初期設計の引き継ぎ文書
