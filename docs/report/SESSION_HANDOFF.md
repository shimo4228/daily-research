# daily-research セッション引き継ぎ

## このドキュメントについて

2026-02-13のセッションで「次の開発プロジェクト」を検討した結果、
daily-researchプロジェクトの設計が固まった。
本ドキュメントは次のセッションへの引き継ぎ用。

---

## プロジェクト概要

毎朝2本のDeep Researchレポートを自動生成し、Obsidianに届ける仕組み。

**目的:** 次に自分が作るべき開発アイデアの発見

---

## 決定済みの要件

| 項目 | 決定 |
|------|------|
| 頻度 | 毎日2本 |
| 分量 | 各~3000字（計30分で読める） |
| レポート1 | テックトレンド（AI自律選定） |
| レポート2 | パーソナル関心：身体性認知科学・仏教（AI自律選定） |
| 共通セクション | 「開発アイデアへの示唆」を両方に含む（交差点を探る） |
| テーマ選定 | AIが自律的に決定 |
| 実行タイミング | 毎朝 AM 5:00（起床前に完成） |
| 閲覧方法 | Obsidian（既存vault、iCloud同期） |
| 運用 | 構築後は読むだけ。手作業ゼロ |
| テーマソース | HN/GitHub Trending/TechCrunch/arxiv + config.tomlで変更可能 |
| プロジェクト名 | daily-research |

## 技術的な決定

| 項目 | 決定 | 理由 |
|------|------|------|
| リサーチエンジン | OpenAI Deep Research API | 公式API（ToSリスクなし）、APIキー所持済み、GPT Researcherより高品質 |
| モデル | `o3-deep-research-2025-06-26` | Deep Research専用モデル |
| レポート整形 | Claude Haiku API | 低コストで整形処理に十分 |
| 蓄積形式 | マークダウン + frontmatter + タグ | Obsidian互換、プラグイン不要 |
| スケジューラ | launchd (macOS) | スリープ中でも起動時に実行される |
| パッケージ管理 | uv + pyproject.toml | ワークスペースの標準パターン |
| エンジン差し替え | config.tomlで切替可能 | Perplexity API等への将来の切替に備える |

## Obsidian vault

```
/Users/shimomoto_tatsuya/Library/Mobile Documents/iCloud~md~obsidian/Documents/Obsidian Vault
```

レポート保存先: `Obsidian Vault/daily-research/`

## 所持済みAPIキー

- [x] OpenAI API
- [x] Anthropic API

---

## 未解決の重要課題（次セッションで最優先）

### テーマ選定とプロンプト設計の深掘り

前セッションの最後に出た指摘:
**「毎日リサーチするとなると、ディープリサーチをかけるトピックとプロンプトが
非常に重要になる。ここをもっと掘り下げないといけない」**

#### 現状の問題点

現在のテーマ選定は「HN/GitHub Trendingからスコアリングで1つ選ぶ」という
シンプルな設計だが、これだと：

1. **表面的になりがち** — トレンド上位は誰でも知っている話題
2. **プロンプトが汎用的** — 「〇〇について調べて」ではDeep Researchの力を引き出せない
3. **自分にとっての価値が不明** — 「流行っている」と「自分に関係がある」は別

#### 良いテーマの条件（仮説）

- まだ自分が知らないこと
- 変化の兆しがあるもの（静的知識より動いている領域）
- 自分のスキル（Python/Swift/TS）と交差しうるもの
- 「ウィスパートレンド」— まだ多くの人が気づいていないが重要な変化

#### プロンプト品質の問題

悪い例: 「MCPサーバーについて調べてください」
良い例: 多角的な観点を指定し、開発アイデアにつながる問いを含めたプロンプト

**テーマが決まった後に、そのテーマに最適化されたプロンプトを動的に生成する層が必要。**

#### 次セッションでの議論ポイント

1. テーマ選定のアルゴリズムをどう設計するか
2. Deep Researchプロンプトの動的生成をどうするか
3. 「自分にとっての価値」をどう定量化するか
4. 30日後、90日後もテーマの質を維持できるか

---

## 関連ファイル

| ファイル | 内容 |
|---------|------|
| `daily-research/PLAN.md` | 実装プラン（全体フロー、構成、config例、実装ステップ） |
| `docs/research-report_ai-research-pipeline.md` | 同上のコピー |

## リサーチで判明した重要事実

### Deep Research APIランドスケープ

| サービス | API | 状態 |
|---------|-----|------|
| OpenAI | `/responses` + `o3-deep-research` | GA |
| Gemini | Interactions API | パブリックベータ |
| Perplexity | `sonar-deep-research` | GA |
| Tavily | Research endpoint | プライベートベータ（SOTA性能） |
| Exa | `/research` endpoint | GA（SimpleQA 94.9%） |

→ 詳細は `~/.claude/skills/learned/deep-research-api-landscape.md`

### マルチエージェント設計の知見（Google Research）

- 独立並列実行: エラー増幅17.2倍
- 中央集権型（オーケストレーター）: エラー増幅4.4倍 ← 推奨
- Fan-out/Fan-inで36〜137倍の速度向上
- Plan-and-Execute（賢いモデルが計画、安いモデルが実行）で90%コスト削減

### コスト最適化パターン

- モデルルーティング: 50-98%削減
- Batch API: 50%オフ
- プロンプトキャッシュ: 90%削減
- Haiku: Sonnetの90%の能力で1/3コスト

---

## インスピレーション元

ポッドキャスト「池友小原のディープなAIニュース」の議論:

**尾原氏のアプローチ:**
- Playwright + ヘッドレスChromeでGemini Deep Researchを自動大量実行（1日200回）
- 結果からキーワード抽出 → 次のリサーチプロンプト自動生成（累乗的リサーチ）
- 全結果をマークダウン + ハッシュタグで蓄積
- NotebookLMでポッドキャスト化 → 2倍速ながら聞き

**池友氏のアプローチ:**
- Manusのワイドリサーチで並列エージェント100体
- パターンを出してから各パターンごとにユースケース大量収集
- Claude Agent Teamでサブエージェント分散

**共通の課題:** 収集・生成はできるが、人間の理解・消化がボトルネック

---

## ユーザーの嗜好（Memory記録済み）

- **実装前に納得いくまで議論する**: 選択肢を急かさない
- **認知負荷を重視**: 大量生成より厳選・消化しやすい量
- **自動化志向**: 構築後は手を動かさず結果だけ受け取りたい
- **関心領域**: テックトレンド + 身体性認知科学 + 仏教
